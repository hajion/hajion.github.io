<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="D:/smark/smark-2.0.2-win32-portable/smark.css" type="text/css" />
  <script src="D:/smark/smark-2.0.2-win32-portable/mathjax/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
<style type="text/css">
  span.MathJax_SVG { zoom : 1.6; }
</style></head>
<body>
<table>
<tbody>
<tr class="odd">
<td align="left">title: &quot;Relationship between GPR and Non-local Means&quot;</td>
</tr>
<tr class="even">
<td align="left">output: html_document</td>
</tr>
</tbody>
</table>
<p>A Gaussian process can be used to describe a distribution over function mappings. GPR is a kernel-based machine learning method, where the covariance function plays as a kernel.</p>
<p>A Gaussian process <span class="math">\(f(x)\)</span> is completely specified by its mean and covariance function, <span class="math">\(f(x)\sim\mathcal{N}(m(x),k(x, x&#39;))\)</span>, where <span class="math">\(m(x)\)</span> is the mean function of <span class="math">\(f(x)\)</span>, and <span class="math">\(k(x,x&#39;)\)</span> is the covariance function between <span class="math">\(f(x)\)</span> and <span class="math">\(f(x&#39;)\)</span>. If the observation on <span class="math">\(x\)</span> is the sum of <span class="math">\(f(x)\)</span> and an additive white Gaussian noise, the model can be denoted as <span class="math">\(y=f(x)+\epsilon,\epsilon \sim \mathcal{N}(0,\sigma_n^2)\)</span>. Suppose the training samples are <span class="math">\(\{(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\}\)</span>, and <span class="math">\(X\)</span>, <span class="math">\(\mathbf{y}\)</span> are denoted as</p>
<p><span class="math">\[X = (x_1,x_2,\cdots,x_n)^T, \mathbf{y} = (y_1,y_2,\cdots,y_n)^T\]</span></p>
<p>The input of test samples is <span class="math">\(X_*=(x_{1_*},x_{2_*},\cdots,x_{n_*})^T\)</span>. We want to predict the corresponding function values <span class="math">\(\mathbf{f_*}=(f(x_{1_*}),f(x_{2_*}),\cdots,f(x_{n_*})^T\)</span> without noise. It is obvious that <span class="math">\((\mathbf{y, f_*})\)</span> is also a joint Gaussian, and the covariance between <span class="math">\(y_p\)</span> and <span class="math">\(y_q\)</span> can be computed as <span class="math">\(\mathrm{cov}(y_p, y_q)=k(x_p,x_q)+\sigma_n^2\delta_{pq}\)</span>. So, if <span class="math">\(\mathbf{y}\)</span> and <span class="math">\(\mathbf{f_*}\)</span> subtract their respective mean values, the joint distribution of <span class="math">\(\mathbf{y}\)</span> and <span class="math">\(\mathbf{f_*}\)</span> according to the prior can be described as</p>
<p><span class="math">\[\begin{matrix}\begin{bmatrix}\mathbf{y}\\ \mathbf{f_*} \end{bmatrix}\end{matrix}\sim \mathcal{N}\begin{matrix}\begin{pmatrix}\mathbf{0},\begin{bmatrix}K(X,X)+\sigma_n^2I &amp; K(X,X_*)\\ K(X_*) &amp; K(X_*,X_*) \end{bmatrix}\end{pmatrix}\end{matrix}\]</span></p>
<p>where <span class="math">\(K(X, X_*)\)</span> denotes the <span class="math">\(n\times n_*\)</span> covariance matrix evaluated at all pairs of training and test samples, and similarly for the other entries <span class="math">\(K_f=K(X,X)\)</span>, <span class="math">\(K(X_*, X)\)</span> and <span class="math">\(K(X_*, X_*)\)</span>. Then the conditional distribution of <span class="math">\(\mathbf{f_*}\)</span> can be inferred as <span class="math">\[\mathbf{f_*}|X,\mathbf{y},X_*\sim \mathcal{N}(\overline{\mathbf{f_*}},\mathrm{cov}(\mathbf{f_*}))\]</span> where <span class="math">\[\overline{\mathbf{f_*}}=\mathbb{E}[\mathbf(f_*)|X,\mathbf{y},X_*]=K(X_*,X)[K(X,X)+\sigma_n^2I]^{-1}\mathbf{y}\]</span></p>
<p><span class="math">\[\mathrm{cov}(\mathbf{f_*})=K(X_*,X_*)-K(X_*,X)[K(X,X)+\sigma_n^2I]^{-1}K(X,X_*)\]</span></p>
<p><span class="math">\(\overline{\mathbf{f_*}}\)</span>, the mean of <span class="math">\(\mathbf(f_*)\)</span>, is the unbiased prediction of <span class="math">\(\mathbf(f_*)\)</span>. So, the prediction of GPR is of statistical significance. Besides, the variance <span class="math">\(\mathrm{cov}(f_*)\)</span> provides the confidence of the <em>prediction</em>.           </p>
</body>
</html>
